{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models as m\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as dist\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device('cuda:0')\n",
    "    dtype = torch.FloatTensor\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    dtype = torch.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "    \n",
    "def t(x):\n",
    "    # j'avais des problèmes de type avec les long \n",
    "    return torch.as_tensor(x, dtype=torch.get_default_dtype()).to(device)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'N_train': 10000,\n",
       " 'EVAL_EVERY': 700,\n",
       " 'lr': 0.001,\n",
       " 'EPS_TRAINNING': False,\n",
       " 'sigma': {'schedule': 'lin',\n",
       "  'min': 0.1,\n",
       "  'max': 1,\n",
       "  'n_sigmas': 10,\n",
       "  'values': [1.0,\n",
       "   0.7742636799812317,\n",
       "   0.5994842648506165,\n",
       "   0.46415889263153076,\n",
       "   0.35938137769699097,\n",
       "   0.2782559394836426,\n",
       "   0.2154434621334076,\n",
       "   0.1668100506067276,\n",
       "   0.1291549652814865,\n",
       "   0.10000000149011612]},\n",
       " 'device': 'cuda:0',\n",
       " 'model': {'in_channel': 1,\n",
       "  'base_ch': 16,\n",
       "  'channel_mults': [1, 2, 4],\n",
       "  'sigma_emb_dim': 16}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "RUNS_ROOT = os.path.join(BASE_PATH, \"runs\")\n",
    "EXP_NAME = \"baseline\"\n",
    "EXP_DIR = os.path.join(RUNS_ROOT, EXP_NAME)\n",
    "RUN_ID = '001'\n",
    "RUN_DIR = os.path.join(EXP_DIR, RUN_ID)  \n",
    "WEIGHTS_DIR = os.path.join(RUN_DIR, \"weights\")\n",
    "LOGS_DIR = os.path.join(RUN_DIR, \"logs\")\n",
    "VIDEO_DIR = os.path.join(RUN_DIR, 'videos')\n",
    "\n",
    "with open(os.path.join(LOGS_DIR, 'hparams.json')) as json_data:\n",
    "    hparams = json.load(json_data)\n",
    "    json_data.close()\n",
    "   \n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMAS = t(hparams['sigma']['values'])\n",
    "EPS_TRAINNING = hparams['EPS_TRAINNING']\n",
    "SCORE_NORM = np.load(os.path.join(LOGS_DIR,'score_norm.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallUNetSigma(\n",
       "  (sigma_emb): SigmaEmbedding(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (3): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (init_conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ResBlock(\n",
       "      (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (down_samples): ModuleList(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (mid_block1): ResBlock(\n",
       "    (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "    (act1): SiLU()\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "    (act2): SiLU()\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (emb_proj1): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    )\n",
       "    (emb_proj2): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "    )\n",
       "    (skip): Identity()\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): ResBlock(\n",
       "      (norm1): GroupNorm(8, 96, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=32, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm1): GroupNorm(8, 48, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(48, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Sequential(\n",
       "    (0): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.load(os.path.join(WEIGHTS_DIR, 'model.pt'),map_location=device,weights_only=True)\n",
    "model = m.SmallUNetSigma(\n",
    "    in_ch=hparams['model']['in_channel'],\n",
    "    base_ch=hparams['model']['base_ch'],\n",
    "    channel_mults=hparams['model']['channel_mults'],  \n",
    "    emb_dim=hparams['model']['sigma_emb_dim'],\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(w)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de gradient ici pour ALD \n",
    "def make_score_from_model(model, sigma_scalar,eps_loss = False):\n",
    "    sigma_scalar = float(sigma_scalar)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def score(x):\n",
    "        # x: (B, x_dim)\n",
    "        B = x.shape[0]\n",
    "        sigma = x.new_full((B, 1), sigma_scalar).to(device)   # (B,1) \n",
    "        return model(x, sigma)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def score_eps(x):\n",
    "       # x: (B, x_dim)\n",
    "        B = x.shape[0]\n",
    "        sigma = x.new_full((B, 1), sigma_scalar)   # (B,1) \n",
    "        return model(x, sigma) /sigma\n",
    "    if eps_loss : \n",
    "        return score_eps\n",
    "    else : \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_distribution_scores = [make_score_from_model(model,noise,EPS_TRAINNING) for noise in list(SIGMAS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_prior = SIGMAS.max().item()  # ou sigmas.max().item()\n",
    "prior_normal = dist.Normal(\n",
    "    loc=torch.tensor(0.0, device=device),\n",
    "    scale=torch.tensor(sigma_prior, device=device),\n",
    ")\n",
    "prior_unif = dist.Uniform(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealded_langevin_sampler_snr(prior, noisy_distrib_scores, noise_factor,\n",
    "                                   SNR, norm, T, n_chain, save_dir=None):\n",
    "    C = 1\n",
    "    H = 28\n",
    "    W = 28\n",
    "    X = prior.sample((n_chain, C, H, W)).to(device)\n",
    "\n",
    "    D = H * W\n",
    "    PLOT_STEP_EVERY = 100           # tu peux changer si tu veux plus/moins de frames\n",
    "    IDX_TO_TRACK = 0              # on suit l'image X[0] dans le temps\n",
    "\n",
    "    if save_dir is not None:\n",
    "        if os.path.exists(save_dir):\n",
    "            shutil.rmtree(save_dir)   # supprime tout ce qu'il y a dedans (et le dossier)\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    frame = 0  # pour numéroter les images\n",
    "\n",
    "    for i in range(len(noisy_distrib_scores)):\n",
    "        tau = 2 * D * SNR / norm[i]\n",
    "        noise_std = math.sqrt(2 * tau)   # niveau de bruit\n",
    "\n",
    "        for step in range(T):\n",
    "\n",
    "            X = X + tau * noisy_distrib_scores[i](X) + noise_std * torch.randn_like(X)\n",
    "\n",
    "            # on sauve régulièrement l'évolution d'UNE SEULE image\n",
    "            if step % PLOT_STEP_EVERY == 0  or (step + 1)% T == 0:\n",
    "                plt.figure(figsize=(3, 3))\n",
    "                img = X[IDX_TO_TRACK].clone().squeeze().detach().cpu()\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                plt.axis('off')\n",
    "                plt.title(\n",
    "                    f\"sigma={noise_factor[i]:.3f} | \"\n",
    "                    f\"SNR={SNR:.2e} | \"\n",
    "                    f\"noise_std={noise_std:.2e} | \"\n",
    "                    f\"step={step}\"\n",
    "                )\n",
    "\n",
    "                if save_dir is not None:\n",
    "                    fname = os.path.join(save_dir, f\"frame_{frame:05d}.png\")\n",
    "                    plt.savefig(fname, dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                frame += 1\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.system(f\"./make_ald_video.sh {save_dir} {SNR} {T}\")\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = os.path.join(VIDEO_DIR,'out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/home/infres/rplanchon-23/code/DSM/src/ncsn/mnist/runs/baseline/001/videos/out//frame_%05d.png':\n",
      "  Duration: 00:00:11.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 767x378 [SAR 5906:5906 DAR 767:378], 10 fps, 10 tbr, 10 tbn, 10 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x562e8b336e00] using SAR=767/766\n",
      "[libx264 @ 0x562e8b336e00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x562e8b336e00] profile High, level 2.2, 4:2:0, 8-bit\n",
      "[libx264 @ 0x562e8b336e00] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/infres/rplanchon-23/code/DSM/src/ncsn/mnist/runs/baseline/001/videos/ald_0.01_1000_video.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 766x378 [SAR 767:766 DAR 767:378], q=2-31, 10 fps, 10240 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  110 fps= 68 q=-1.0 Lsize=     572kB time=00:00:10.70 bitrate= 438.1kbits/s speed=6.64x    \n",
      "video:570kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.375688%\n",
      "[libx264 @ 0x562e8b336e00] frame I:1     Avg QP:20.42  size: 10920\n",
      "[libx264 @ 0x562e8b336e00] frame P:28    Avg QP:26.78  size:  6060\n",
      "[libx264 @ 0x562e8b336e00] frame B:81    Avg QP:28.42  size:  4968\n",
      "[libx264 @ 0x562e8b336e00] consecutive B-frames:  0.9%  1.8%  2.7% 94.5%\n",
      "[libx264 @ 0x562e8b336e00] mb I  I16..4: 11.8% 39.4% 48.8%\n",
      "[libx264 @ 0x562e8b336e00] mb P  I16..4:  1.7%  3.3% 30.9%  P16..4:  4.5%  3.4%  1.9%  0.0%  0.0%    skip:54.3%\n",
      "[libx264 @ 0x562e8b336e00] mb B  I16..4:  1.8%  2.8% 23.1%  B16..8:  5.1%  6.5%  2.1%  direct: 1.6%  skip:56.9%  L0:48.5% L1:39.3% BI:12.3%\n",
      "[libx264 @ 0x562e8b336e00] 8x8 transform intra:10.7% inter:51.1%\n",
      "[libx264 @ 0x562e8b336e00] coded y,uvDC,uvAC intra: 60.5% 0.0% 0.0% inter: 12.8% 0.0% 0.0%\n",
      "[libx264 @ 0x562e8b336e00] i16 v,h,dc,p: 78% 20%  2%  1%\n",
      "[libx264 @ 0x562e8b336e00] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 53% 20% 15%  1%  0%  0%  0%  1%  9%\n",
      "[libx264 @ 0x562e8b336e00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 65% 27%  5%  0%  1%  0%  1%  0%  1%\n",
      "[libx264 @ 0x562e8b336e00] i8c dc,h,v,p: 100%  0%  0%  0%\n",
      "[libx264 @ 0x562e8b336e00] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x562e8b336e00] ref P L0: 49.0% 10.5% 21.9% 18.6%\n",
      "[libx264 @ 0x562e8b336e00] ref B L0: 70.8% 20.5%  8.7%\n",
      "[libx264 @ 0x562e8b336e00] ref B L1: 88.3% 11.7%\n",
      "[libx264 @ 0x562e8b336e00] kb/s:424.03\n"
     ]
    }
   ],
   "source": [
    "SNR = 0.001\n",
    "ALD_estimated_score_snr = annealded_langevin_sampler_snr(\n",
    "    prior_normal,\n",
    "    estimated_distribution_scores,\n",
    "    SIGMAS,\n",
    "    0.01,\n",
    "    SCORE_NORM,\n",
    "    T = 1000,\n",
    "    n_chain=1,\n",
    "    save_dir=OUTDIR\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
