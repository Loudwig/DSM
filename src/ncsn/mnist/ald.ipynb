{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models as m\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as dist\n",
    "import numpy as np\n",
    "import math\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    device = torch.device('cuda:0')\n",
    "    dtype = torch.FloatTensor\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    dtype = torch.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "    \n",
    "def t(x):\n",
    "    # j'avais des problèmes de type avec les long \n",
    "    return torch.as_tensor(x, dtype=torch.get_default_dtype()).to(device)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'N_epoch': 30,\n",
       " 'EVAL_EVERY': 300,\n",
       " 'lr': 0.0001,\n",
       " 'EPS_TRAINNING': False,\n",
       " 'sigma': {'schedule': 'lin',\n",
       "  'min': 0.01,\n",
       "  'max': 1,\n",
       "  'n_sigmas': 10,\n",
       "  'values': [1.0,\n",
       "   0.8899999856948853,\n",
       "   0.7799999713897705,\n",
       "   0.6700000166893005,\n",
       "   0.5600000023841858,\n",
       "   0.44999998807907104,\n",
       "   0.3400000035762787,\n",
       "   0.23000000417232513,\n",
       "   0.11999999731779099,\n",
       "   0.009999999776482582]},\n",
       " 'device': 'cuda:0',\n",
       " 'model': {'in_channel': 1,\n",
       "  'base_ch': 64,\n",
       "  'channel_mults': [1, 2, 4],\n",
       "  'sigma_emb_dim': 16}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "RUNS_ROOT = os.path.join(BASE_PATH, \"runs\")\n",
    "EXP_NAME = \"test\"\n",
    "EXP_DIR = os.path.join(RUNS_ROOT, EXP_NAME)\n",
    "RUN_ID = '004'\n",
    "RUN_DIR = os.path.join(EXP_DIR, RUN_ID)  \n",
    "WEIGHTS_DIR = os.path.join(RUN_DIR, \"weights\")\n",
    "LOGS_DIR = os.path.join(RUN_DIR, \"logs\")\n",
    "VIDEO_DIR = os.path.join(RUN_DIR, 'videos')\n",
    "\n",
    "with open(os.path.join(LOGS_DIR, 'hparams.json')) as json_data:\n",
    "    hparams = json.load(json_data)\n",
    "    json_data.close()\n",
    "   \n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMAS = t(hparams['sigma']['values'])\n",
    "EPS_TRAINNING = hparams['EPS_TRAINNING']\n",
    "SCORE_NORM = np.load(os.path.join(LOGS_DIR,'score_norm.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallUNetSigma(\n",
       "  (sigma_emb): SigmaEmbedding(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      (3): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (init_conv): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): ResBlock(\n",
       "      (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (skip): Identity()\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=128, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=128, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=256, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=256, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (down_samples): ModuleList(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (mid_block1): ResBlock(\n",
       "    (norm1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "    (act1): SiLU()\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "    (act2): SiLU()\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (emb_proj1): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=16, out_features=256, bias=True)\n",
       "    )\n",
       "    (emb_proj2): Sequential(\n",
       "      (0): SiLU()\n",
       "      (1): Linear(in_features=16, out_features=256, bias=True)\n",
       "    )\n",
       "    (skip): Identity()\n",
       "  )\n",
       "  (up_samples): ModuleList(\n",
       "    (0): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): ResBlock(\n",
       "      (norm1): GroupNorm(8, 384, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=128, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=128, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm1): GroupNorm(8, 192, eps=1e-05, affine=True)\n",
       "      (act1): SiLU()\n",
       "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (act2): SiLU()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (emb_proj1): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (emb_proj2): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=16, out_features=64, bias=True)\n",
       "      )\n",
       "      (skip): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (out_conv): Sequential(\n",
       "    (0): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.load(os.path.join(WEIGHTS_DIR, 'model.pt'),map_location=device,weights_only=True)\n",
    "model = m.SmallUNetSigma(\n",
    "    in_ch=hparams['model']['in_channel'],\n",
    "    base_ch=hparams['model']['base_ch'],\n",
    "    channel_mults=hparams['model']['channel_mults'],  \n",
    "    emb_dim=hparams['model']['sigma_emb_dim'],\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(w)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pas de gradient ici pour ALD \n",
    "def make_score_from_model(model, sigma_scalar,eps_loss = False):\n",
    "    sigma_scalar = float(sigma_scalar)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def score(x):\n",
    "        # x: (B, x_dim)\n",
    "        B = x.shape[0]\n",
    "        sigma = x.new_full((B, 1), sigma_scalar).to(device)   # (B,1) \n",
    "        return model(x, sigma)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def score_eps(x):\n",
    "       # x: (B, x_dim)\n",
    "        B = x.shape[0]\n",
    "        sigma = x.new_full((B, 1), sigma_scalar)   # (B,1) \n",
    "        return model(x, sigma) /sigma\n",
    "    if eps_loss : \n",
    "        return score_eps\n",
    "    else : \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_distribution_scores = [make_score_from_model(model,noise,EPS_TRAINNING) for noise in list(SIGMAS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_prior = SIGMAS.max().item()  # ou sigmas.max().item()\n",
    "prior_normal = dist.Normal(\n",
    "    loc=torch.tensor(0.0, device=device),\n",
    "    scale=torch.tensor(sigma_prior, device=device),\n",
    ")\n",
    "prior_unif = dist.Uniform(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealded_langevin_sampler_snr(prior, noisy_distrib_scores, noise_factor,\n",
    "                                   SNR, norm, T, n_chain, save_dir=None):\n",
    "    C = 1\n",
    "    H = 28\n",
    "    W = 28\n",
    "    X = prior.sample((n_chain, C, H, W)).to(device)\n",
    "\n",
    "    D = H * W\n",
    "    PLOT_STEP_EVERY = 100           # tu peux changer si tu veux plus/moins de frames\n",
    "    IDX_TO_TRACK = [u for u in range(n_chain)]              # on suit l'image X[0] dans le temps\n",
    "\n",
    "    if save_dir is not None:\n",
    "        if os.path.exists(save_dir):\n",
    "            shutil.rmtree(save_dir)   # supprime tout ce qu'il y a dedans (et le dossier)\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    frame = 0  # pour numéroter les images\n",
    "\n",
    "    for i in range(len(noisy_distrib_scores)):\n",
    "        tau = 2 * D * SNR / norm[i]\n",
    "        noise_std = math.sqrt(2 * tau)   # niveau de bruit\n",
    "\n",
    "        for step in range(T):\n",
    "\n",
    "            X = X + tau * noisy_distrib_scores[i](X) + noise_std * torch.randn_like(X)\n",
    "\n",
    "            # on sauve régulièrement l'évolution d'UNE SEULE image\n",
    "            if ((step + 1) % T == 0 ) or ((step +1) % PLOT_STEP_EVERY == 0) or step == 0 :\n",
    "                plt.figure(figsize=(3*len(IDX_TO_TRACK), 3*len(IDX_TO_TRACK)))\n",
    "                for y,z in enumerate(IDX_TO_TRACK) : \n",
    "                    plt.subplot(1,len(IDX_TO_TRACK),y+1)\n",
    "                    img = X[z].clone().squeeze().detach().cpu()\n",
    "                    plt.imshow(img, cmap='gray')\n",
    "                    plt.axis('off')\n",
    "                plt.title(\n",
    "                    f\"sigma={noise_factor[i]:.3f} | \"\n",
    "                    f\"SNR={SNR:.2e} | \"\n",
    "                    f\"noise_std={noise_std:.2e} | \"\n",
    "                    f\"step={step}\"\n",
    "                )\n",
    "\n",
    "                if save_dir is not None:\n",
    "                    fname = os.path.join(save_dir, f\"frame_{frame:05d}.png\")\n",
    "                    plt.savefig(fname, dpi=150, bbox_inches='tight', pad_inches=0)\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    plt.show()\n",
    "\n",
    "                frame += 1\n",
    "\n",
    "    if save_dir is not None:\n",
    "        os.system(f\"./make_ald_video.sh {save_dir} {SNR} {T}\")\n",
    "\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = os.path.join(VIDEO_DIR,'out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from '/home/infres/rplanchon-23/code/DSM/src/ncsn/mnist/runs/test/004/videos/out//frame_%05d.png':\n",
      "  Duration: 00:00:21.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 3723x327 [SAR 5906:5906 DAR 1241:109], 10 fps, 10 tbr, 10 tbn, 10 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x555a037e8740] using SAR=1787/1792\n",
      "[libx264 @ 0x555a037e8740] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0x555a037e8740] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x555a037e8740] 264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/infres/rplanchon-23/code/DSM/src/ncsn/mnist/runs/test/004/videos/ald_0.002_2000_video.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 3722x326 [SAR 202283:202849 DAR 1241:109], q=2-31, 10 fps, 10240 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  210 fps= 13 q=-1.0 Lsize=    8731kB time=00:00:20.70 bitrate=3455.4kbits/s speed=1.29x       \n",
      "video:8728kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.039228%\n",
      "[libx264 @ 0x555a037e8740] frame I:1     Avg QP:24.70  size: 61490\n",
      "[libx264 @ 0x555a037e8740] frame P:55    Avg QP:24.81  size: 50226\n",
      "[libx264 @ 0x555a037e8740] frame B:154   Avg QP:26.50  size: 39694\n",
      "[libx264 @ 0x555a037e8740] consecutive B-frames:  1.0%  3.8%  0.0% 95.2%\n",
      "[libx264 @ 0x555a037e8740] mb I  I16..4: 13.8% 11.0% 75.2%\n",
      "[libx264 @ 0x555a037e8740] mb P  I16..4:  3.8%  6.3% 48.0%  P16..4:  8.0%  7.4%  5.5%  0.0%  0.0%    skip:21.0%\n",
      "[libx264 @ 0x555a037e8740] mb B  I16..4:  3.1%  2.9% 23.1%  B16..8: 14.2% 11.9%  8.5%  direct: 9.7%  skip:26.8%  L0:44.5% L1:35.4% BI:20.1%\n",
      "[libx264 @ 0x555a037e8740] 8x8 transform intra:10.3% inter:52.9%\n",
      "[libx264 @ 0x555a037e8740] coded y,uvDC,uvAC intra: 74.9% 0.0% 0.0% inter: 42.5% 0.0% 0.0%\n",
      "[libx264 @ 0x555a037e8740] i16 v,h,dc,p: 82% 16%  1%  1%\n",
      "[libx264 @ 0x555a037e8740] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 49% 21% 22%  2%  1%  1%  1%  1%  3%\n",
      "[libx264 @ 0x555a037e8740] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 56% 32%  6%  1%  1%  1%  1%  1%  1%\n",
      "[libx264 @ 0x555a037e8740] i8c dc,h,v,p: 100%  0%  0%  0%\n",
      "[libx264 @ 0x555a037e8740] Weighted P-Frames: Y:9.1% UV:0.0%\n",
      "[libx264 @ 0x555a037e8740] ref P L0: 36.7% 18.7% 26.1% 18.2%  0.3%\n",
      "[libx264 @ 0x555a037e8740] ref B L0: 75.0% 18.6%  6.4%\n",
      "[libx264 @ 0x555a037e8740] ref B L1: 90.4%  9.6%\n",
      "[libx264 @ 0x555a037e8740] kb/s:3404.47\n"
     ]
    }
   ],
   "source": [
    "for SNR in [0.002] : \n",
    "    ALD_estimated_score_snr = annealded_langevin_sampler_snr(\n",
    "        prior_normal,\n",
    "        estimated_distribution_scores,\n",
    "        SIGMAS,\n",
    "        SNR,\n",
    "        SCORE_NORM,\n",
    "        T = 2000,\n",
    "        n_chain=10,\n",
    "        save_dir=OUTDIR\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testpip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
